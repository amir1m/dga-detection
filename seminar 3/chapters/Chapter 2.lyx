#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass ociamthesis-lyx
\begin_preamble
\usepackage{array}
\usepackage{graphicx}
\usepackage{multirow}

\newcommand\MyBox[2]{
  \fbox{\lower0.75cm
    \vbox to 1.7cm{\vfil
      \hbox to 1.7cm{\hfil\parbox{1.4cm}{#1\\#2}\hfil}
      \vfil}%
  }%
}

\renewcommand\[{\begin{equation}}
\renewcommand\]{\end{equation}}
\usepackage{caption}
\end_preamble
\options a4paper,titlepage
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize 12
\spacing onehalf
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 0
\use_package mathdots 0
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine natbib
\cite_engine_type numerical
\biblio_style plainnat
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 2
\tocdepth 2
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Chapter
Literature Survey 
\end_layout

\begin_layout Section
Related Work
\end_layout

\begin_layout Standard
KÃ¼hrer et al.
 
\begin_inset CommandInset citation
LatexCommand citep
key "kuhrer2014paint"
literal "false"

\end_inset

 evaluated the public and vendor provided blacklist based approach to blocking
 malicious domain names.
 They found that these blacklist contained only 20% of major domains from
 malware families and failed to provide any protection against AGD names.
 Antonakakis et al.
 
\begin_inset CommandInset citation
LatexCommand citep
key "antonakakis2012throw"
literal "false"

\end_inset

 suggested clustering and classification based approach to process the domain
 names in respective DGA families.
 Bahnsen et al.
 
\begin_inset CommandInset citation
LatexCommand citep
key "bahnsen2017classifying"
literal "false"

\end_inset

 evaluated random forest based classifiers with feature engineering versus
 Recurrent Neural Network (RNN) for classifying phishing URLs and found
 RNNs to be more superior in performance compared to random forest based
 models.
 Woodbridge et al.
 
\begin_inset CommandInset citation
LatexCommand citep
key "woodbridge2016predicting"
literal "false"

\end_inset

 used Long Short Term Memory (LSTM) architecture to detect the AGD names.
 Their proposed method improved accuracy of detection however faced challenges
 when it comes to dictionary or wordlist based DGA.
 Detecting malicious domain names on real time and inline traffic has been
 a challenge.
 Yu et al.
 
\begin_inset CommandInset citation
LatexCommand citep
key "yu2017inline"
literal "false"

\end_inset

 proposed a system for inline AGD detection at the DNS server end using
 Convolutional Neural Network (CNN) and LSTM based approach.
 A hybrid neural network approach comprising of parallel CNN and attention
 based Bi-LSTM layers was designed by Yang et al.
 
\begin_inset CommandInset citation
LatexCommand citep
key "yang2020detecting"
literal "false"

\end_inset

 as shown in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Hybrid-DNN-Architecture"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 The problem was first converted to binary classification of benign and
 malicious URLs.
 For multiclass classification they were able to obtain an macro averaging
 F1 score of 0.7653 with proposed hybrid architecture.
\begin_inset Note Note
status open

\begin_layout Plain Layout
For comparative results
\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename ../../dga-paper/figures/yang2020detecting_HDNN.png
	scale 65

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Hybrid-DNN-Architecture"

\end_inset

Hybrid DNN Architecture by Yang et al.
\end_layout

\end_inset


\end_layout

\end_inset

 Another similar approach utilizing attention based mechanism was proposed
 by Fangali et al.
 
\begin_inset CommandInset citation
LatexCommand cite
key "ren2020dga"
literal "false"

\end_inset

 that uses CNN, Bi-LSTM and Attention layer after the embedding layer to
 do the detection as well as multiclass classification of various DGAs as
 shown in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:ATT-CNN-BiLSTM-model-proposed"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../../dga-paper/figures/Fangali_ATT-CNN-BiLSTM.png
	scale 60

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:ATT-CNN-BiLSTM-model-proposed"

\end_inset

ATT-CNN-BiLSTM model proposed by Fangali et al.
\begin_inset CommandInset citation
LatexCommand cite
key "ren2020dga"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset

 They obtained micro average F1 score of 0.89 and macro average score of
 0.83 on more than 20 real world AGD name list and legitimate domain name
 lists including word list based DGAs such as 
\emph on
matsnu
\emph default
 and 
\emph on
suppobox
\emph default
.
\begin_inset Note Note
status open

\begin_layout Plain Layout
For comparative results
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Since wordlist based attacks are based on relatively small number of list
 of words, Patsakis and Casino
\begin_inset CommandInset citation
LatexCommand cite
key "patsakis2021exploiting"
literal "false"

\end_inset

 applied a probabilistic approach for AGD detection.
 Iwahana et al.
 
\begin_inset CommandInset citation
LatexCommand cite
key "iwahana2021madmax"
literal "false"

\end_inset

proposed Extreme Learning Machine based browser plugin for real time malicious
 URL detection.
 However, as shown in Figure they rely on feature extraction from text of
 domain name, DNS records and web based features such as WHOIS lifespan
 information.
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename ../../dga-paper/figures/Iwahana_ELM.png
	scale 60

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Browser-based-AGD"

\end_inset

Browser based AGD detection by Iwahana et al.
 
\begin_inset CommandInset citation
LatexCommand cite
key "iwahana2021madmax"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Overall, the advances in Natural Language Processing has fueled success
 in encountering malicious DGA starting from RNN and leading up to attention
 based deep learning models.
 However, as suggested by Yu et al.
 
\begin_inset CommandInset citation
LatexCommand cite
key "yu2018character"
literal "false"

\end_inset

 simpler character embedded models are preferred since more complex RNN,
 LSTM based models are prone to overfitting and simpler models are faster
 to train and test.
 Findings from our own experiments as outlined in this paper also underscore
 the same principle with newer, complex models.
\end_layout

\end_body
\end_document

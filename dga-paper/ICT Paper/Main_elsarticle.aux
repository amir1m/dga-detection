\relax 
\providecommand\hyper@newdestlabel[2]{}
\bbl@cs{beforestart}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\emailauthor{mukeriamir@gmail.com}{Amir Mukeri \corref {cor1}}
\emailauthor{dpgaikwad@aissmscoe.com}{Dwarkoba Gaikwad\corref {cor2}}
\Newlabel{cor1}{1}
\citation{kuhrer2014paint}
\citation{antonakakis2012throw}
\citation{woodbridge2016predicting}
\citation{yu2017inline}
\citation{yang2020detecting}
\citation{ren2020dga}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{1}{section.2}\protected@file@percent }
\@writefile{brf}{\backcite{kuhrer2014paint}{{1}{2}{section.2}}}
\@writefile{brf}{\backcite{antonakakis2012throw}{{1}{2}{section.2}}}
\@writefile{brf}{\backcite{woodbridge2016predicting}{{1}{2}{section.2}}}
\@writefile{brf}{\backcite{yu2017inline}{{1}{2}{section.2}}}
\@writefile{brf}{\backcite{yang2020detecting}{{1}{2}{section.2}}}
\@writefile{brf}{\backcite{ren2020dga}{{1}{2}{section.2}}}
\citation{vaswani2017attention}
\citation{devlin2018bert}
\citation{zago2020umudga}
\citation{yang2020detecting}
\citation{ren2020dga}
\@writefile{toc}{\contentsline {section}{\numberline {3}Methodology}{2}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Transformers and Bidirectional Encoder Representations from Transformer(BERT)}{2}{subsection.3.1}\protected@file@percent }
\@writefile{brf}{\backcite{vaswani2017attention}{{2}{3.1}{subsection.3.1}}}
\newlabel{eq:AttentionEquation}{{1}{2}{Transformers and Bidirectional Encoder Representations from Transformer(BERT)}{equation.3.1}{}}
\@writefile{brf}{\backcite{devlin2018bert}{{2}{3.1}{equation.3.1}}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Fine tuning of pre-trained BERT model using labelled dataset\relax }}{2}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:BERT-fine-tuning}{{1}{2}{Fine tuning of pre-trained BERT model using labelled dataset\relax }{figure.caption.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Experimental Results and Discussion}{2}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Dataset}{2}{subsection.4.1}\protected@file@percent }
\@writefile{brf}{\backcite{zago2020umudga}{{2}{4.1}{subsection.4.1}}}
\citation{yang2020detecting}
\citation{ren2020dga}
\bibstyle{elsarticle-num}
\bibdata{bao}
\bibcite{kuhrer2014paint}{{1}{}{{}}{{}}}
\bibcite{antonakakis2012throw}{{2}{}{{}}{{}}}
\bibcite{woodbridge2016predicting}{{3}{}{{}}{{}}}
\bibcite{yu2017inline}{{4}{}{{}}{{}}}
\bibcite{yang2020detecting}{{5}{}{{}}{{}}}
\bibcite{ren2020dga}{{6}{}{{}}{{}}}
\bibcite{vaswani2017attention}{{7}{}{{}}{{}}}
\bibcite{devlin2018bert}{{8}{}{{}}{{}}}
\bibcite{zago2020umudga}{{9}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces BERT model AGD(1) vs Legitimate(0) domain name detection confidence. Value of 0.5 was used as threshold, shown as orange line.\relax }}{3}{figure.caption.3}\protected@file@percent }
\newlabel{fig:BERT-detection-confidence}{{2}{3}{BERT model AGD(1) vs Legitimate(0) domain name detection confidence. Value of 0.5 was used as threshold, shown as orange line.\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}DGA Detection}{3}{subsection.4.2}\protected@file@percent }
\@writefile{brf}{\backcite{yang2020detecting}{{3}{4.2}{table.caption.2}}}
\@writefile{brf}{\backcite{ren2020dga}{{3}{4.2}{table.caption.2}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}DGA Classification}{3}{subsection.4.3}\protected@file@percent }
\@writefile{brf}{\backcite{yang2020detecting}{{3}{4.3}{subsection.4.3}}}
\@writefile{brf}{\backcite{ren2020dga}{{3}{4.3}{subsection.4.3}}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{3}{section.5}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Detection results on test data. BERT outperforms all the other models. P:Precision, R:Recall.\relax }}{4}{table.caption.2}\protected@file@percent }
\newlabel{tab:Results-Detection}{{1}{4}{Detection results on test data. BERT outperforms all the other models. P:Precision, R:Recall.\relax }{table.caption.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Results on test data. Dictionary based DGAs are in bold. P:Precision, R:Recall\relax }}{4}{table.caption.4}\protected@file@percent }
\newlabel{tab:Results-on-test}{{2}{4}{Results on test data. Dictionary based DGAs are in bold. P:Precision, R:Recall\relax }{table.caption.4}{}}
